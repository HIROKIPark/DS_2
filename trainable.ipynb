{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 Import\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 학습에 사용되는 자잘한 것들\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    \"\"\"\n",
    "    모델 구조 수정 금지.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoding_dim, cat_features, num_features, num_classes, cat_cardinalities):\n",
    "        super(BaseModel, self).__init__()\n",
    "        # cat_cardinalities는 각 범주형 변수의 고유값 개수 리스트\n",
    "        self.cat_embeddings = nn.ModuleList([nn.Embedding(cardinality, 5) for cardinality in cat_cardinalities])\n",
    "        self.fc_cat = nn.Linear(len(cat_features) * 5 + len(num_features), 64)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_cat, x_num):\n",
    "        # Apply embedding layers\n",
    "        embeddings = [emb(x_cat[:, i]) for i, emb in enumerate(self.cat_embeddings)]\n",
    "        #print('len(embeddings : )',len(embeddings))\n",
    "        #print('len(x_num) : ',len(x_num))\n",
    "        x = torch.cat(embeddings + [x_num], dim=1)\n",
    "        #print('len(x) : ',len(x))\n",
    "        x = self.fc_cat(x)\n",
    "        encoded = self.encoder(x)\n",
    "        out = self.classifier(encoded)\n",
    "        # print(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_standardize_data(data, mode):\n",
    "    label_encoders = {}\n",
    "    categorical_columns_train = ['Card Brand', 'Card Type', 'Card Number', 'Expires', 'Acct Open Date', 'Is Fraud?', 'Error Message']\n",
    "    categorical_columns_test = ['Card Brand', 'Card Type', 'Card Number', 'Expires', 'Acct Open Date', 'Error Message']\n",
    "    data['Error Message'] = data['Error Message'].fillna('None')\n",
    "    categorical_columns = categorical_columns_train if mode == 'Train' else categorical_columns_test\n",
    "\n",
    "    cat_cardinalities = []\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "        label_encoders[col] = le\n",
    "        cat_cardinalities.append(data[col].nunique())\n",
    "\n",
    "    data['Zipcode'] = (data['Zipcode'] // 100).astype(int)\n",
    "    le_zipcode = LabelEncoder()\n",
    "    data['Zipcode'] = le_zipcode.fit_transform(data['Zipcode'])\n",
    "    cat_cardinalities.append(data['Zipcode'].nunique())\n",
    "\n",
    "    data['Merchandise Code'] = (data['Merchandise Code'] // 100).astype(int)\n",
    "    le_merchandise_code = LabelEncoder()\n",
    "    data['Merchandise Code'] = le_merchandise_code.fit_transform(data['Merchandise Code'])\n",
    "    cat_cardinalities.append(data['Merchandise Code'].nunique())\n",
    "\n",
    "    data['Has Chip'] = np.where(data['Has Chip'] == True, 1, 0)\n",
    "    cat_cardinalities.append(data['Has Chip'].nunique())\n",
    "\n",
    "    data['Birth Year'] = data['Birth Year'] - data['Birth Year'].min()\n",
    "    data['Year PIN last Changed'] = data['Year PIN last Changed'] - data['Year PIN last Changed'].min()\n",
    "\n",
    "    # Continuous columns for StandardScaler\n",
    "    continuous_columns = [\n",
    "        'Current Age', 'Retirement Age', 'Birth Year', 'Birth Month', 'Per Capita Income - Zipcode',\n",
    "        'Yearly Income', 'Total Debt', 'Credit Score', 'Credit Limit', 'Year', 'Month', 'Day', 'Amount'\n",
    "    ]\n",
    "    scaler = StandardScaler()\n",
    "    data[continuous_columns] = scaler.fit_transform(data[continuous_columns])\n",
    "\n",
    "    # Identify categorical and numerical features\n",
    "    categorical_columns += ['Zipcode', 'Merchandise Code', 'Has Chip']\n",
    "    cat_features = data[categorical_columns].astype(int)  # Ensure categorical features are integer\n",
    "    num_features = data[continuous_columns]\n",
    "\n",
    "    return cat_features, num_features, cat_cardinalities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "x_cat_train, x_num_train, cat_cardinalities_train = encode_and_standardize_data(train_data, mode='Train')\n",
    "x_cat_test, x_num_test, cat_cardinalities_test = encode_and_standardize_data(test_data, mode='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_cat_test.iloc[1], x_num_test.iloc[1], cat_cardinalities_test,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch tensor로 변환\n",
    "x_cat_train_tensor = torch.tensor(x_cat_train.values, dtype=torch.long)  # 정수형\n",
    "x_num_train_tensor = torch.tensor(x_num_train.values, dtype=torch.float32)  # 실수형\n",
    "\n",
    "x_cat_test_tensor = torch.tensor(x_cat_test.values, dtype=torch.long)\n",
    "x_num_test_tensor = torch.tensor(x_num_test.values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2  # 예: Is Fraud? 이진 분류\n",
    "encoding_dim = 64 # 이게 이제 \n",
    "\n",
    "model = BaseModel(encoding_dim=encoding_dim, cat_features=x_cat_train.columns, num_features=x_num_train.columns, num_classes=num_classes, cat_cardinalities=cat_cardinalities_train)\n",
    "\n",
    "# 모델 출력 테스트\n",
    "output = model(x_cat_train_tensor, x_num_train_tensor)\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-Test Split\n",
    "x_cat_train_split, x_cat_val_split, x_num_train_split, x_num_val_split = train_test_split(\n",
    "    x_cat_train_tensor, x_num_train_tensor, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Dataset 및 DataLoader 정의\n",
    "train_dataset = torch.utils.data.TensorDataset(x_cat_train_split, x_num_train_split)\n",
    "val_dataset = torch.utils.data.TensorDataset(x_cat_val_split, x_num_val_split)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Loss Function, Optimizer 정의\n",
    "criterion = nn.CrossEntropyLoss()  # 다중 클래스 분류의 경우\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train Loop 구현\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10):\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for x_cat_batch, x_num_batch in train_loader:\n",
    "            optimizer.zero_grad()  # 기울기 초기화\n",
    "            outputs = model(x_cat_batch, x_num_batch)\n",
    "            loss = criterion(outputs, torch.randint(0, 2, (x_cat_batch.size(0),)))  # 임시 타겟 (예: binary class)\n",
    "            loss.backward()  # 역전파\n",
    "            optimizer.step()  # 가중치 업데이트\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "        # Validation Loop\n",
    "        model.eval()  # 모델을 평가 모드로 설정\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x_cat_batch, x_num_batch in val_loader:\n",
    "                outputs = model(x_cat_batch, x_num_batch)\n",
    "                loss = criterion(outputs, torch.randint(0, 2, (x_cat_batch.size(0),)))  # 임시 타겟\n",
    "                val_loss += loss.item()\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "        model.train()  # 다시 학습 모드로 전환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "model = BaseModel(\n",
    "    encoding_dim=64,\n",
    "    cat_features=x_cat_train.columns,\n",
    "    num_features=x_num_train.columns,\n",
    "    num_classes=2,  # 이진 분류\n",
    "    cat_cardinalities=cat_cardinalities_train\n",
    ")\n",
    "\n",
    "# 학습 실행\n",
    "train_model(model, train_loader, val_loader, num_epochs=10)\n",
    "\n",
    "# Test Data 평가\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(x_cat_test_tensor, x_num_test_tensor)\n",
    "    print(\"Test Outputs:\", outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
